from torch.optim.adamw import AdamW
from torch_geometric.nn import GAE
from model import Classifier, Encoder, ModelArgs
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
learning_rate = 0.01
epochs = 100

def train_encoder(encoder: GAE, optimizer: AdamW) -> None:
    encoder.train()
    # TODO: fix this when we have access to data samples
    data = []
    for graph in data:
        pred = encoder.encode(graph, edge_idx)


def test_encoder(encoder: GAE) -> None:
    encoder.eval()

def train_classifier(classifier: Classifier, optimizer: AdamW) -> None:
    classifier.train()

def test_classifier(classifier: Classifier) -> None:
    classifier.eval()

def main() -> None:
    # TODO: replace with "real" values i.e. in_channels=num_features
    args = ModelArgs(in_channels=100, out_channels=200, hidden_scaling_factor=1.5)
    autoencoder = GAE(Encoder(args)).to(device)
    encoder_optim = torch.optim.AdamW(autoencoder.parameters(), lr=learning_rate)

    classifier = Classifier(args.out_channels, int(args.out_channels * args.hidden_scaling_factor), 2)
    classifier_optim = torch.optim.AdamW(classifier.parameters(), lr=learning_rate)
    
    for epoch in range(1, epochs + 1):
        train_encoder(autoencoder, encoder_optim)

    for epoch in range(1, epochs + 1):
        train_classifier(classifier, classifier_optim)

if __name__ == "__main__":
    main()
