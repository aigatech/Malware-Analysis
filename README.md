# Malware-Analysis

## Methodology
Using Static Analysis (deconstruction of binaries without execution) to extract Control Flow Graphs from a binary.

Leverage Graph Neural Networks trained on these CFGs to classify an arbitrary binary as malicious or benign.
We aim to primarily utilize a dataset of 200k+ Windows PE binaries [linked here](https://practicalsecurityanalytics.com/pe-malware-machine-learning-dataset/)

## Goal
Produce a pipeline capable of performing deconstruction + inference in a **very fast timespan**. Feature based models (i.e. XGBoost -> tree model, Yara Rules -> condition matching) can run in <1s and NLP tools (i.e. Kilogram paper -> n-gram analysis) can also run fairly fast. Our hypothesis is that GNNs can capture more complex characteristics of malicious binaries via their CFGs and by training a large model and compressing it to a smaller downstream one, we can match the accuracy of feature based approaches with a fairly close inference time as well.

## Compression Techniques

TBD - do more research here. Added potential ones but requires more insight
- Distillation (teaching a smaller downstream model to learn the behavior of the large model; famous from DistilBERT)
- Quantization (possibly quantization aware training to facilitate this approach)
- Pruning (self explanatory; remove weights determined as irrelevant by some arbitrary technique)
- Theoretical Optimization based on BERT-of-Theseus paper
  - Paper is centered around replacing large BERT modules with small modules while training to get small modules to mimic behavior of large ones in network
  - Depends on GNN architecture but could this be applied here? Can we have an optimization method where modules with 50%, 75% less params than large-GNN modules are randomly inserted in some trained network and trained to mimic the role of the large modules (similar to distillation but incorporated in the network)?
